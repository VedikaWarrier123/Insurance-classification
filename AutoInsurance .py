# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14xbHtIzy4weqVmIr1fwid1X1JB1JPOZz
"""

!pip install jenkspy

# Import Libraries
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score, rand_score, adjusted_rand_score
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder, StandardScaler, PowerTransformer

from jenkspy import JenksNaturalBreaks
from yellowbrick.cluster import KElbowVisualizer

# Uploading files
from google.colab import files
uploaded = files.upload()

# Data frame saving
df = pd.read_csv('AutoInsurance.csv')
df.tail()

# Noting all columns of data frame
X = df.columns.values.tolist()
print(X)

# Label encoding
label_encoder = LabelEncoder()

def encoder(st):
  df[st]= label_encoder.fit_transform(df[st])
  df[st].unique()

d = df.dtypes
j = 0
for i in d:
  if(i == object):
    encoder(X[j])
  j+=1
df.head()

# Removing the unwanted columns
X.remove('Customer')
X.remove('Effective To Date')
print(X)

# Convert data into array
data=df[X].to_numpy()
print(data)

# Defining the elbow Method
def elbow_method(data):
  Elbow_M = KElbowVisualizer(KMeans(), locate_elbow=True, metric = 'silhouette')
  Elbow_M.fit(data)
  Elbow_M.show()
  return

# Function for Plotting Clusters
def plot_clusters(n, cluster_pred_values,data):
  for x in range(n):
    cname = "cluster " + str(x)
    plt.scatter(
      data[cluster_pred_values == x, 0], data[cluster_pred_values == x, 1],
      s=50, c=np.random.rand(3,),
      edgecolor='black',
      label= cname)

# Function for Plotting Centroid (K-Means)
def plot_centroids(km_model):
  plt.scatter(
    km_model.cluster_centers_[:, 0], km_model.cluster_centers_[:, 1],
    s=100, marker='o',
    c='black', edgecolor='black',
    label='centroids')

# Clustering algorithm
def k_means_clustering(n_clust,data):
  km = KMeans(n_clusters= n_clust, init='random',
    n_init=10, max_iter=300,
    tol=1e-04, random_state=0)

  km_predict = km.fit_predict(data)

  # Silhouette Score
  s_score = silhouette_score(data, km.labels_, metric = 'euclidean')
  print('Silhouette Score for',n_clust,'Cluster K-Means Clustering:', s_score)

  # Plot the data
  plot_clusters(n_clust, km_predict, data)
  plot_centroids(km)
  plt.legend(scatterpoints=1,loc = (1.1,0.5))
  plt.show()

# for the subsets
def k_means_clust(n_clust,data):
  km = KMeans(n_clusters= n_clust, init='random',
    n_init=10, max_iter=300,
    tol=1e-04, random_state=0)

  km_predict = km.fit_predict(data)

  # Silhouette Score
  s_score = silhouette_score(data, km.labels_, metric = 'euclidean')
  return(s_score)

jnb = JenksNaturalBreaks()

# Defining the jnb clustering algorithm
def jnb_clustering(n_clust,data,X):
    s = dict()
    for i in range(0,len(X)):
        #fit the model
        unique_values = len(np.unique(data[:,i]))
        if unique_values >= n_clust:
            jnb.fit(data[:,i])

            # Silhouette Score
            s_score = silhouette_score(data, jnb.labels_, metric = 'euclidean')
            s[X[i]] = s_score
            print('Silhouette Score for',X[i],'- JNB Clustering:', s_score)

        else:
            print(f"Skipping clustering for column '{X[i]}' as the number of unique values ({unique_values}) is less than the requested number of clusters ({n_clust}).")

    return(sorted(s.items(), key=lambda kv: (kv[1], kv[0])))

# Plotting the result with elbow method
elbow_method(df[X])

# Clustering for 2 clusters using k-means
s = k_means_clustering(2,data)

# Clustering for 2 clusters using JNB
s = jnb_clustering(2,data,X)

# Denoting scores of each feature
from tabulate import tabulate
print("The Silhouette scores of JNB Clustering based on the features:")
df1 = pd.DataFrame(s,columns =['Features','Silhouette Score'])
print(tabulate(df1, headers = 'keys', tablefmt = 'fancy_grid'))

# Set a threshold value of 0.1
threshold = 0.1
X = []
for i in s:
    if i[1] > 0:
        X.append(i[0])
X

# Sub-List of Features
def sub_lists(l):
  lists = [[]]
  for i in range(len(l) + 1):
    for j in range(i):
      lists.append(l[j: i])
  for sub_arr in lists:
      if len(sub_arr) < 1:
        lists.remove(sub_arr)
  return lists

sblst = sub_lists(X)
sblst

# Denoting the scores of clusters
s_score_Kmeans = []
for i in sblst:
  data = df[i].to_numpy()
  s = k_means_clust(2,data)
  s_score_Kmeans.append([i,s])

# Noting scores of features
print("The Silhouette scores of K Clustering based on the features:")
df2 = pd.DataFrame.from_dict(s_score_Kmeans)
print(tabulate(df2, headers = ['Features','Sihouette Score'], tablefmt = 'fancy_grid'))

from sklearn.decomposition import PCA

scaling=StandardScaler()

scaling.fit(df)
Scaled_data=scaling.transform(df)

# Set the n_components=3
principal=PCA(n_components=3)
principal.fit(Scaled_data)
x=principal.transform(Scaled_data)

# Check the dimensions of data after PCA
print(x.shape)

# Scatter of the features
plt.figure(figsize=(10,10))
plt.scatter(x[:,1],x[:,0],c=df['Income'],cmap='plasma')
plt.xlabel('pc1')
plt.ylabel('pc2')

elbow_method(df[X])

# Clustering for 4 clusters using k-means
s = k_means_clustering(4,x)

# Clustering for 2 clusters using k-means
s = k_means_clustering(2,x)